# 评测技术报告

## 一、项目背景

随着大语言模型（Large Language Models, LLMs）在自然语言处理、教育、科研等多个领域中的广泛应用，如何准确、系统地评估其能力成为当前人工智能评测领域的关键课题。由于模型能力评估往往受限于提示词设计的有效性与规范性，错误的提示词往往会导致模型输出格式混乱、信息提取失败等问题，从而影响评测的准确性和公平性。

## 二、评测目标与问题分析

### 2.1 评测目标

- 构建一套高一致性、高稳定性的模型评测系统；
- 提升模型输出答案的可解析性；
- 减少因模型格式混乱而导致的评测偏差；
- 自动提取模型在选择题任务中的答案信息，适用于单选题和多选题。

### 2.2 存在问题

通过实测发现，多个模型在面对选择题时输出存在以下问题：

1. **输出格式混乱**：如未按JSON格式输出、未明确给出“正确选项”等字段；
2. **遗漏答案**：模型可能仅提供了解释而没有明确指出正确选项；
3. **答案不唯一或前后矛盾**：部分模型会输出多个选项，或者多次回答给出不同答案；
4. **内容偏离任务目标**：部分模型回答的内容冗长或包含与任务无关的信息，导致信息提取失败。

上述问题严重影响了自动化评测系统的提取一致性和评分准确性。

## 三、系统方案设计

为解决上述问题，研究提出了三阶段提示词优化策略，具体如下：

### 3.1 基础提示词优化

在提示词中引入以下要素：

- **任务角色**（如“答题模型”）；
- **任务说明**（说明是“选择一个正确答案”）；
- **输出格式规范**（严格要求输出JSON结构）；
- **示例引导**（提供范例输出，减少理解歧义）；
- **引导思维链**（如“think step by step”）增强推理性。

### 3.2 多样化提示词生成与比较

基于上述结构，利用大模型（如GPT）自动生成多个提示词样例。通过对比不同模型（如glm-4-9b-chat、Yi-1.5-6B-Chat等）在165道选择题上的输出表现，评估各提示词的提取一致率，筛选出效果最优的提示词结构。

### 3.3 补充提取机制设计

为应对部分模型仍输出不规范答案的情况，设计了基于大模型的“答案抽取器”子模块。该模块接收问题与模型原始输出，返回标准格式中的“正确选项”，增强了系统的容错性与提取成功率。

